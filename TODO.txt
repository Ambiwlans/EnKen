###########
CUR
###########        

-?

+++++++++++
MAIN
+++++++++++

Tweaking:
    ? for doing prediction, could pre-bin and avg the data (size50?) and make assumptions about empty bins (l/r of mid)
        - current issue is that empty sections get 0 weight resulting in flatter
        - doing this could weaken the granularity of the data
        - could add in binned data to normal data
        - adaptive bin size based on # of answers?
            - size = 10k/#q
            - so with 100 answers, we'd be adding 100 bins of size 100, this almost definitely improves results
        - is this worth doing when results are currently good enough?
        - would need to change the regularization all over again
    - to old bounds prediction was sort of better (took slope into account), maybe tune it to line up w/ new data?            
    ? question selection should change slope to be flatter?
    
DB:
    + add wikitags, toefl, grade level estimates, categories? (like 'medical','archaic')       
        - many-many relational table (<1 tag/word)
    ? save pred to testlog
    - join data from wiki
        ? paste in defns over 'alt of'.... (everything under 15letter defns?)
        ? easy way to swap definitions to ones from wiki
        + need to keep under 5MB limit
    - test_log should ideally store num_known as well instead of just using 'a' which isn't quite accurate for comparisons
        
Front end:
	- new 'help' button images
    	- reenable button
    - report definition button
        ? popup that allows user to reccomend a definition
            + puts the text into a log (word id + suggestion) i can check manually later
        ? simply adds the word to a list to check (no security risks, less space, easy)
    ? weirdly the q word resizer still only supports up to 22 characters (longest word on list atm is Overscrupulousness (18))
    
History:
    - export list to anki
    ? show user other tests from same ip. links, graph
    ? better catches for bad links
    ?? grey out continue button after it would be predicted to time out
    - 'wrong' list filter by tags
    - Add a reading level estimate w/ links to recommended reading (or study material at lower levels)
    - More history flav text
         - more quotes
         - Semipalmated flocculent hygrometry soliloquize erective sparge Roquelaure dunner pavior trousseau
         http://www.chrisjoneswriting.com/terry-pratchett-quotes/category/language
     
Bugs:
    - switch from deprecated to_msgpack (use pyarrow?)
    ? words at extremes aren't reshuffling w/ l2r (like entest)
    ?? forcemetaupdate throwing a timeout with no error msgs... randomly twice, then it worked fine. (was cpu sleeping?)
    - hitting f5 shouldn't post during test
        - are we correctly only recording the first time?
    
Study Mode:
    ? settings for # of repeats, etc.
    ? Give an animation when one of them goes up
    ? Only add words to study if they are near or below current prediction (should know)
    
Misc:
	+ beta testing
	
CORE/BOTH:
    - update packages/python, trim reqs
    ? identify magic numbers w/ inline comments
    - move scheduler times into config
    - add a full reset fn to admin page (set config TEST_TIMEOUT to 0, force update)

+++++++++++
    
Fork (Keep jiken in mind EVERY git commit):
    + go through git log to find changes to push across
    
+++++++++++
LATER
+++++++++++
+ reduce step size for l2r
+ set test timeout back to 1hr
+ refactor views.py ... it is a gross mess. needs comments too
+ reexamine the range prediction based on more data
+ histogram
    - put histogram into history
    
+++++++++++
MAYBE
+++++++++++
? change to a left side, rightside algorithm to fit, rather than sigmoid
? log blocks of questions in test and drop this table entirely? (incorrect way to do it, but handles the 10k cap better)
? change colour scheme? Dark mode?
? merger of all testing thingies? Select a from and to (kanji->english, eng->eng) .... some losses from going generic, easier to maintain, harder to build... vocab only?
? Add categories for top 25 'topics' from wiktionary data set, enable this in history somehow